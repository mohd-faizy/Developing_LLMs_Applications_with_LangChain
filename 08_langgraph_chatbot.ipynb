{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0667f7",
   "metadata": {},
   "source": [
    "# â­**Dynamic Chat Agents**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd288318",
   "metadata": {},
   "source": [
    "\n",
    "## Table of Contents\n",
    "\n",
    "- [***1. Introduction to Graph-Based Chatbots***](#1-introduction-to-graph-based-chatbots)\n",
    "- [***2. Building an Agent with LangGraph***](#2-building-an-agent-with-langgraph)\n",
    "- [***3. Streaming Responses***](#3-streaming-responses)\n",
    "- [***4. Adding External Tools***](#4-adding-external-tools)\n",
    "- [***5. Adding Memory***](#5-adding-memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766dd429",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup cell: Importing all necessary modules\n",
    "\n",
    "from typing import Annotated\n",
    "from typing_extensions import TypedDict\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed47eaae",
   "metadata": {},
   "source": [
    "\n",
    "## 1. Introduction to Graph-Based Chatbots\n",
    "\n",
    "LangGraph enables the construction of agentic chatbots by defining workflows as stateful graphs.\n",
    "\n",
    "### Key Concepts\n",
    "\n",
    "- **Graph State**: Controls tool usage and the order of execution.\n",
    "- **Agent State**: Tracks the task completion and maintains conversation history.\n",
    "- **Nodes**: Functions or tool calls.\n",
    "- **Edges**: Rules that direct the graph from one node to another.\n",
    "- Pre-built nodes include START and END.\n",
    "\n",
    "- ðŸ“Œ *Think of a graph as a map of decisions or steps a chatbot takes when responding to user input.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be0bb8e",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Building an Agent with LangGraph\n",
    "\n",
    "We define a language model, a state type, and initialize the LangGraph system.\n",
    "\n",
    "### Define the LLM and State\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cdc79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell initializes the language model\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\", api_key=\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb2bdfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell defines the State structure for the graph\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3b99ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell initializes the graph builder\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae3f337",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the chatbot response function\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "# Add chatbot node to the graph\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e003302a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define edges between START -> chatbot -> END\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "\n",
    "# Compile the graph\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34ec8e3",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Streaming Responses\n",
    "\n",
    "LangGraph supports streaming responses which allow for real-time feedback.\n",
    "\n",
    "### Function to Stream Events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fa4471",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function streams chatbot responses\n",
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\n",
    "        for value in event.values():\n",
    "            print(\"Agent:\", value[\"messages\"])\n",
    "\n",
    "# Example query\n",
    "user_query = \"Who is Mary Shelley?\"\n",
    "stream_graph_updates(user_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70541e8",
   "metadata": {},
   "source": [
    "\n",
    "## 4. Adding External Tools\n",
    "\n",
    "LangGraph supports integration with tools such as Wikipedia.\n",
    "\n",
    "### Add Wikipedia Tool\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99399926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Wikipedia API tool\n",
    "api_wrapper = WikipediaAPIWrapper(top_k_results=1)\n",
    "wikipedia_tool = WikipediaQueryRun(api_wrapper=api_wrapper)\n",
    "tools = [wikipedia_tool]\n",
    "\n",
    "# Bind tools to LLM\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Update chatbot to use tool\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e1a787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add chatbot and tool nodes\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "tool_node = ToolNode(tools=[wikipedia_tool])\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "# Add conditional edge and routing\n",
    "graph_builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f35a43",
   "metadata": {},
   "source": [
    "\n",
    "## 5. Adding Memory\n",
    "\n",
    "LangGraph can persist conversations using memory modules.\n",
    "\n",
    "### Configure Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a472cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize memory and compile the graph\n",
    "memory = MemorySaver()\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d768d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for streaming with memory\n",
    "def stream_memory_responses(user_input: str):  \n",
    "    config = {\"configurable\": {\"thread_id\": \"single_session_memory\"}}\n",
    "    for event in graph.stream({\"messages\": [(\"user\", user_input)]}, config):\n",
    "        for value in event.values():\n",
    "            if \"messages\" in value and value[\"messages\"]:\n",
    "                print(\"Agent:\", value[\"messages\"])\n",
    "\n",
    "# Streaming sample queries\n",
    "stream_memory_responses(\"What is the Colosseum?\")\n",
    "stream_memory_responses(\"Who built it?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
